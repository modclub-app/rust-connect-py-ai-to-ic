type ModelInferenceResult = variant {
    Ok: vec float32;
    Err: text;
};

type ResultRecord = record {
    outputs: vec float32;
    shapes: vec nat64;
};

type ModelInferenceMid = variant {
    Ok: ResultRecord;
    Err: text;
};


type TensorInput = variant {
    F32: vec float32;
    I64: vec int64;
};

service : {
    "model_inference": (vec int64) -> (ModelInferenceResult);
    "model_sub_compute": (nat8, TensorInput, vec nat64)  -> (ModelInferenceMid) query;
    "setup_model": () -> (opt text);
    "upload_model_bytes_chunks": (vec nat8) -> ();
    "upload_wasm_ref_cell_length": () -> (nat64) query;
    "upload_wasm_ref_cell_clear": () -> ();
    "pipeline_init": () -> ();
    "pipeline_clear": () -> ();
}
